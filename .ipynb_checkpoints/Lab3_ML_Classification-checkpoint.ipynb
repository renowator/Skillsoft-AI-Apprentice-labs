{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Apprentice Lab 3 Solution\n",
    "#### Machine Learning Classification\n",
    "\n",
    "1. The dataset provided is described below \n",
    "2. Use basic Python packages for numeric computing\n",
    "3. Separate features from labels\n",
    "4. Split data for training and testing\n",
    "5. Train RandomForestClassifier from sklearn.ensemble \n",
    "6. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      IMPORT REQUIRED LIBRARIES\n",
    "import pandas\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import glob\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of all files in the dataset\n",
    "all_files = glob.glob(\"Data/murphy/learn/learn/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information\n",
    "\n",
    "1. TITLE: Artificial Character Database\n",
    "\n",
    "2. SOURCES: \n",
    "                   Marco Botta\n",
    "\t\t   Dipartimento di Informatica\n",
    "\t\t   Universita` di Torino\n",
    "\t\t   Corso Svizzera 185\n",
    "                   10149  Torino\n",
    "                   ITALY\n",
    "                   Tel. (+39)(11)7712002\n",
    "                   Fax. (+39)(11)751603\n",
    "                   email: botta@di.unito.it\n",
    "                   July, 1992\n",
    "\n",
    "3. PAST USAGE:\n",
    "    (a) M. Botta, A. Giordana, L. Saitta: \"Learning Fuzzy Concept Definitions\",\n",
    "\tsubmitted to IEEE-Fuzzy Conference.\n",
    "\n",
    "\tWe made three type of experiments: we run Smart+ by using default\n",
    "\tvalues for the parameter constants in the fuzzy definitions of the\n",
    "\tpredicates, a local optimization algorithm and a genetic algorithm\n",
    "\tto automatically acquire parameter values. The local optimization\n",
    "\talgorithm and the GA are also described in:\n",
    "\n",
    "\tM. Botta, A. Giordana: \"Learning Quantitative Feature in a Symbolic\n",
    "\tEnvironment\", LNAI 542, 1991, pp. 296-305.\n",
    "\n",
    "\tThe results obtained on this data sets are the following:\n",
    "\n",
    "\tType of Optimization  Recognition Rate  Error Rate  Ambiguity Rate\n",
    "\t  \n",
    "\t  No OPT\t\t  41.48%\t   3.82%\t 54.70%\n",
    "\t  Loacl OPT\t\t  98.68%\t   0.12%\t  1.20%\n",
    "\t  Local+GA OPT\t\t  99.70%\t   0.0%\t\t  0.30%\n",
    "\n",
    "4. RELEVANT INFORMATION:\n",
    "\n",
    "      This database has been artificially generated by using a first order\n",
    "      theory which describes the structure of ten capitol letters of the\n",
    "      English alphabet and a random choice theorem prover which accounts\n",
    "      for etherogeneity in the instances. The capitol letters represented\n",
    "      are the following: A, C, D, E, F, G, H, L, P, R.\n",
    "      Each instance is structured and is described by a set of segments (lines)\n",
    "      which resemble the way an automatic program would segment an image.\n",
    "      Each instance is stored in a separate file whose format is the following:\n",
    "              CLASS OBJNUM TYPE XX1 YY1 XX2 YY2 SIZE DIAG\n",
    "      where CLASS is an integer number indicating the class as described below,\n",
    "      OBJNUM is an integer identifier of a segment (starting from 0) in the\n",
    "      instance and the remaining columns represent attribute values.\n",
    "      For further details contact the author.\n",
    "\n",
    "5. NUMBER OF INSTANCES:\n",
    "      1000 instance (100 per class) as learning set.\n",
    "      5000 instance (500 per class) as test set.\n",
    "\n",
    "6. NUMBER OF ATTRIBUTES:\n",
    "      Each segment in an instance is described by seven attributes, four of\n",
    "      which are the most important, one is superflous, and the other two can be\n",
    "      computed from the important ones, but are present for efficiency reasons.\n",
    "\n",
    "7. ATTRIBUTE INFORMATION:\n",
    "\n",
    "      TYPE: the first attribute describes the type of segment and is always\n",
    "\t    set to the string \"line\". Its C language type is char.\n",
    "\n",
    "      XX1,YY1,XX2,YY2: these attributes contain the initial and final coordinates\n",
    "\t\t   of a segment in a cartesian plane. Their C language type is\n",
    "\t\t   int.\n",
    "\n",
    "      SIZE: this is the length of a segment computed by using the geometric\n",
    "\t    distance between two points A(X1,Y1) and B(X2,Y2). Its C language\n",
    "\t    type is float.\n",
    "\n",
    "      DIAG: this is the length of the diagonal of the smallest rectangle\n",
    "\t    which includes the picture of the character. The value of this\n",
    "\t\tattribute is the same in each object. Its C language\n",
    "\t\ttype is float.\n",
    "\n",
    "8. MISSING ATTRIBUTE VALUES: None\n",
    "\n",
    "9. CLASS DISTRIBUTION:\n",
    "        the class value (CLASS) can take ten different values. Each \n",
    "\tletter belongs to only one of classes.\n",
    "\n",
    "\n",
    "        CLASS\tNAME  TRAINING  TESTING  TOTAL     \n",
    "\n",
    "          1\t  A \t100\t  500\t  600\n",
    "          2\t  C\t100\t  500\t  600\n",
    "          3\t  D\t100\t  500\t  600\n",
    "          4\t  E\t100\t  500\t  600\n",
    "          5\t  F\t100\t  500\t  600\n",
    "          6\t  G\t100\t  500\t  600\n",
    "          7\t  H\t100\t  500\t  600\n",
    "          8\t  L\t100\t  500\t  600\n",
    "          9\t  P\t100\t  500\t  600\n",
    "          10\t  R\t100\t  500\t  600\n",
    "          -----------------------------------------------------------\n",
    "          TOTAL        1000      5000    6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into Python and change data types\n",
    "data = pandas.DataFrame()\n",
    "for  filename in all_files:\n",
    "    df = pandas.read_csv(filename, header=None, delim_whitespace= True)\n",
    "    data = data.append(df)\n",
    "for i, dtypes in enumerate(data.dtypes):\n",
    "    if dtypes == \"float64\":\n",
    "        data[i] = data[i].astype(np.float32)\n",
    "    elif dtypes == \"int64\":\n",
    "        data[i] = data[i].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5109 entries, 0 to 7\n",
      "Data columns (total 9 columns):\n",
      "0    5109 non-null int32\n",
      "1    5109 non-null int32\n",
      "2    5109 non-null object\n",
      "3    5109 non-null int32\n",
      "4    5109 non-null int32\n",
      "5    5109 non-null int32\n",
      "6    5109 non-null int32\n",
      "7    5109 non-null float32\n",
      "8    5109 non-null float32\n",
      "dtypes: float32(2), int32(6), object(1)\n",
      "memory usage: 239.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "data = data.drop(2,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's separate features from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels in column 0\n",
    "labels = data[0]\n",
    "features = data.drop(0, axis=1)\n",
    "labels = pandas.DataFrame(labels.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are ready to train a Classification algorithm to predict the a written character by its metrics:\n",
    "#### First, separate the dataset for training and testing and load all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      IMPORT REQUIRED LIBRARIES\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.3, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, we can create a classification model, for this excersize let's use a Random Forest classification approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renowator/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create and train RandomForestClassifier\n",
    "RFClassifier = RandomForestClassifier(n_estimators = 200)\n",
    "RFClassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model is trained now, we can evaluate its performance using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9944071588366891\n",
      "\n",
      "\n",
      "Test Accuracy: 0.6086105675146771\n"
     ]
    }
   ],
   "source": [
    "#Obtain model accuracy on testing and training data\n",
    "test_pred = RFClassifier.predict(x_test)\n",
    "train_pred = RFClassifier.predict(x_train)\n",
    "print(\"Train Accuracy:\", metrics.accuracy_score(y_train, train_pred))\n",
    "print(\"\\n\\nTest Accuracy:\", metrics.accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Created by Nicholas Stepanov: https://github.com/renowator*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
