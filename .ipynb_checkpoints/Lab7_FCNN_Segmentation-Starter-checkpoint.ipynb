{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Apprentice Lab 7 Starter Code\n",
    "#### Fully Convolutional Neural Network Semantic Segmentation\n",
    "\n",
    "1. Normalize the pixel values and labels\n",
    "2. Create encoding Convolutional block for FCNN model\n",
    "3. Add a 1x1 Convolution\n",
    "4. Create decoding ConvTranspose block for FCNN model\n",
    "5. Add several 1x1 convolution and finish with grayscale size of original image\n",
    "6. Separate training and testing data\n",
    "7. Train the FCNNmodel on training data\n",
    "8. Evaluate and visualize results\n",
    "\n",
    "Resources:\n",
    "\n",
    "https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1 - Fully Convolutional Neural Networks (we will use simplest architecture)\n",
    "\n",
    "https://keras.io/api/layers/convolution_layers/convolution2d_transpose/\n",
    "\n",
    "https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class\n",
    "\n",
    "https://keras.io/api/layers/activations/#elu-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      IMPORT REQUIRED LIBRARIES\n",
    "import pandas\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This routine will load images and augmented images into dataset\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "datalist = []\n",
    "labellist = []\n",
    "base_path = \"Data/Semantic dataset100/\"\n",
    "label = 0\n",
    "\n",
    "for subdir, dir, files in os.walk(base_path):\n",
    "    if subdir == base_path:\n",
    "        continue\n",
    "    elif subdir == \"Data/Semantic dataset100/image\":\n",
    "        for image_path in glob.glob(subdir + \"/*.jpg\"):\n",
    "            img = cv2.imread(image_path)\n",
    "            img = img.astype(\"int16\")\n",
    "            if img.shape[0] != 321:\n",
    "                img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            img = cv2.resize(img, (480,320))\n",
    "            #Original image data\n",
    "            datalist.append(img)\n",
    "            #Augmented data\n",
    "            datalist.append(np.fliplr(img))\n",
    "            datalist.append(np.flipud(img))\n",
    "            #Use 180 rotation\n",
    "            img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            datalist.append(img)\n",
    "            #Augmented data \n",
    "            datalist.append(np.fliplr(img))\n",
    "            datalist.append(np.flipud(img))\n",
    "    elif subdir == \"Data/Semantic dataset100/ground-truth\":\n",
    "        for image_path in glob.glob(subdir + \"/*.png\"):\n",
    "            img = cv2.imread(image_path, 0)\n",
    "            img = img.astype(\"int16\")\n",
    "            if img.shape[0] != 321:\n",
    "                img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            img = cv2.resize(img, (480,320))\n",
    "            #Original image data\n",
    "            labellist.append(img)\n",
    "            #Augmented\n",
    "            labellist.append(np.fliplr(img))\n",
    "            labellist.append(np.flipud(img))\n",
    "            #Use 180 rotation\n",
    "            img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            labellist.append(img)\n",
    "            #Augmented data\n",
    "            labellist.append(np.fliplr(img))\n",
    "            labellist.append(np.flipud(img))\n",
    "datalist = np.array(datalist)\n",
    "labellist = np.array(labellist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Berkeley dataset for Semantic Segmentation: https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/ contains pixel-by-pixel 0-255 data which we need to normalize to feed into neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Normalize data values for training (0-255 -> 0 - 1)\n",
    "\n",
    "#TODO: Perform Binary segmentation - change label pixels to binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can create a simple Fully Convolutional Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################---------  INSTANTIATE SEQUENTIAL THE MODEL  --------######################################\n",
    "import keras\n",
    "FCNNmodel = keras.Sequential()\n",
    "############################################################################################################\n",
    "#TODO: Stack Convolutional, AlphaDropout and BatchNormalization layers in a sequence\n",
    "#       Increase the amount of filters used, use 'elu' activation and 'same' padding\n",
    "#       Number of strides per convolutional layer - (2,2)\n",
    "#       Add a MaxPooling layer in the end\n",
    "\n",
    "\n",
    "#TODO:  Add a 1x1 convolutional layer with strides=(1,1) and kernel=(1,1)\n",
    "\n",
    "\n",
    "#TODO: Stack ConvolutionalTranspose and BatchNormalization layers in a sequence\n",
    "#       Decrease the amount of filters used, use 'elu' activation and 'same' padding\n",
    "#       Number of strides per convolutional layer - (2,2)\n",
    "\n",
    "\n",
    "\n",
    "#TODO: Finish the model with several 1x1 convolutions, final output of convolution shape should be (320,480,1)\n",
    "\n",
    "\n",
    "# Adding the final layers of the model. Sigmoid activation makes output in the range of 0-1 for binary values\n",
    "FCNNmodel.add(keras.layers.Reshape(target_shape=(320,480)))\n",
    "FCNNmodel.add(keras.layers.Activation(keras.activations.sigmoid))\n",
    "##############################################################################################################\n",
    "#################---------            COMPILE THE MODEL         --------######################################\n",
    "FCNNmodel.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics = ['binary_accuracy'])\n",
    "FCNNmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Split the dataset for training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Train the FCNNmodel on training data. Adjust the batch_size according to your machine\n",
    "#      The training will take some time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#This function will plot Images generated by segmentation network as well as ground truth and input image\n",
    "def plot_gen(x, y, n_ex=16,dim=(20,3), figsize=(30,40)):\n",
    "    iou = 0\n",
    "    generated_images = FCNNmodel.predict(x)\n",
    "    j = 0\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],j+1)\n",
    "        plt.imshow(x[i])\n",
    "        plt.axis('off')\n",
    "        plt.subplot(dim[0],dim[1],j+2)\n",
    "        img = np.zeros([320,480])\n",
    "        img[:,:] = generated_images[i]\n",
    "        plt.imshow(img*255, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.subplot(dim[0],dim[1],j+3)\n",
    "        plt.imshow(y[i]*255, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        j=j+3\n",
    "        if iou == 0:\n",
    "            iou = iou_score(img,y[i])\n",
    "        iou = (iou + iou_score(img,y[i]))/2\n",
    "        if j>=60:\n",
    "            break\n",
    "    print(\"Image:                    Prediction:                           Truth:\\n\")\n",
    "    plt.show()\n",
    "    print(\"Overall Intersection over Union score: \", iou)\n",
    "\n",
    "    \n",
    "# This function will calculate the IntersectionOverUnion score for a particular prediction   \n",
    "def iou_score(target, prediction):\n",
    "    intersection = np.logical_and(target, prediction)\n",
    "    union = np.logical_or(target, prediction)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the function provided above you can visualize your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Visualize the results of your first Fully Convolutional Neural Network\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Created by Nicholas Stepanov: https://github.com/renowator*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
